---

## ğŸ§¾ License

<p align="center">
  <img src="https://img.shields.io/badge/LICENSE-MIT-green?style=for-the-badge&logo=balance-scale&logoColor=white" alt="MIT License"/>
</p>

<p align="center">
  Distributed under the <a href="LICENSE">MIT License</a>.  
  See <a href="LICENSE">LICENSE</a> file for more details.
</p>

---


## ğŸ“¦ Features

- ğŸ§± **Declarative IaC**: Jobs & DLT pipelines modelled in YAML under `resources/`.
- ğŸ” **Environment Promotion**: Single artifact built once, promoted across **DEV â†’ TEST â†’ PROD**.
- ğŸ” **Run-as SPN**: All deployments use Azure AD **Service Principal** (non-interactive & secure).
- âœ… **Validation**: `databricks bundle validate` in build; `bundle deploy` in each environment.
- ğŸ§¾ **Unity Catalog Ready**: Catalog & schema injected via variables.
- âš™ï¸ **Autoscaling Clusters**: Node types and min/max workers parameterised.

---

## ğŸ“ Repository Structure
```bash
.
â”œâ”€â”€ resources
â”‚   â”œâ”€â”€ jobs
â”‚   â”‚   â”œâ”€â”€ Absence Data.yaml              # Job: Notebook task â†’ DLT task
â”‚   â”‚   â””â”€â”€ Absence Spells Test.yaml
â”‚   â””â”€â”€ pipelines
â”‚       â”œâ”€â”€ Absence Data DLT.yaml          # DLT pipeline config
â”‚       â””â”€â”€ Absence Spells Test DLT.yaml
â”œâ”€â”€ templates
â”‚   â”œâ”€â”€ main.yaml                          # Build â†’ DeployToDev â†’ DeployToTest
â”‚   â””â”€â”€ deployment.yaml                    # Generic deploy (param: buildEnv)
â”œâ”€â”€ databricks.yml                         # DAB bundle & targets (env vars injected)
â”œâ”€â”€ fixtures/.gitkeep                      # Example snippet for loading CSV fixtures (docs)
â””â”€â”€ README.md

âš™ï¸ How It Works
Build (AzDO)
Install Databricks CLI.
Replace placeholders inside databricks.yml with env values from Variable Groups.
databricks bundle validate -t <ENV> to sanity check.
Publish DatabricksBundle artifact.
Deploy (AzDO)
Download artifact and re-inject env values (DEV/TEST/PROD).
az login with Service Principal.
databricks bundle deploy -t <ENV> to create/update Jobs & DLT Pipelines.
Already have objects in the workspace? Bind once
databricks bundle deployment bind -t <env> <resource-name> <existing-id> --auto-approve

Prerequisites
âœ… Azure Databricks workspaces for DEV/TEST/PROD
âœ… Azure AD Service Principal with workspace access
âœ… Azure DevOps Project + Variable Groups per env:
Dab_DEV_Dbw_Variables, Dab_Test_Dbw_Variables, â€¦
âœ… Variables defined (per env):
workspaceUrl, deployEnv, prefixNotebookPath, storageAccount, container, folderPath, existingClusterId, DLTClusterNodeType, DLTMinWorkers, DLTMaxWorkers, DLTSchema, catalog, successEmailDL, failureEmailDL, clientid, clientsecret, tenantid
